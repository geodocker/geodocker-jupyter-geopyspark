{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. [Dependencies](https://spacenetchallenge.github.io/#Dependencies)\n",
    "> The [AWS Command Line Interface (CLI)](https://aws.amazon.com/cli/) must be installed with an active AWS account. Configure the AWS CLI using ‘aws configure’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. [Accessing the SpaceNet Data on AWS](https://aws.amazon.com/public-datasets/spacenet/#Accessing_the_SpaceNet_Data_on_AWS)\n",
    "> The SpaceNet dataset is being released in several Areas of Interest. All AOIs will follow a similar directory structure and data format. The imagery is GeoTIFF satellite imagery and corresponding GeoJSON building footprints...\n",
    "\n",
    "> For more detailed information on how to access specific files within the dataset, see [here](https://github.com/SpaceNetChallenge/utilities/tree/master/content/download_instructions).\n",
    "\n",
    "> _The spacenet-dataset S3 bucket is provided as a Requester Pays bucket, see [here](https://docs.aws.amazon.com/AmazonS3/latest/dev/RequesterPaysBuckets.html) for more information._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Downloading Rio raster and vector data with [Boto](https://boto3.readthedocs.io/en/latest/index.html)\n",
    "Since the bucket is Request Pays, we cannot successfully curl images. Instead, Boto, the AWS SDK for Python, provides an interface to download files from Request Pays buckets. The [S3Transfer](https://boto3.readthedocs.io/en/latest/reference/customizations/s3.html#boto3.s3.transfer.S3Transfer) class has a download method that can take in a 'RequestPayer' argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up paths for download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "bucket = \"spacenet-dataset\"\n",
    "\n",
    "aoi_path = \"AOI_1_Rio\"\n",
    "aoi_data_path = os.path.join(aoi_path, \"srcData\")\n",
    "building_labels_path = os.path.join(aoi_data_path, \"buildingLabels\")\n",
    "mosaic_3band_path = os.path.join(aoi_data_path, \"mosaic_3band\")\n",
    "\n",
    "tmp_path = \"/tmp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Boto for download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client(\"s3\")\n",
    "transfer = boto3.s3.transfer.S3Transfer(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting list of imagery files to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mosaic_3band_object_list = client.list_objects_v2(\n",
    "    Bucket=bucket, Prefix=mosaic_3band_path,\n",
    "    RequestPayer='requester')\n",
    "mosaic_3band_key_list = [obj[\"Key\"] for obj in mosaic_3band_object_list[\"Contents\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Rio imagery files, if not downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mosiac_3band_key in mosaic_3band_key_list:\n",
    "    mosiac_3band_name = mosiac_3band_key.split(\"/\")[-1]\n",
    "    mosiac_3band_filename = os.path.join(tmp_path, mosiac_3band_name)\n",
    "    if (not os.path.isfile(mosiac_3band_filename)):\n",
    "        transfer.download_file(\n",
    "            bucket=bucket, key=mosiac_3band_key, filename=mosiac_3band_filename,\n",
    "            extra_args={\"RequestPayer\": \"requester\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Rio outline, if not downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outline_filename = \"Rio_OUTLINE_Public_AOI.geojson\"\n",
    "outline_key = os.path.join(building_labels_path, outline_filename)\n",
    "full_outline_filename = os.path.join(tmp_path, outline_filename)\n",
    "\n",
    "if (not os.path.isfile(full_outline_filename)):\n",
    "    transfer.download_file(\n",
    "        bucket=bucket, key=outline_key,filename=full_outline_filename,\n",
    "        extra_args={\"RequestPayer\": \"requester\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Rio building footprints file, if not downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "buildings_filename = \"Rio_Buildings_Public_AOI_v2.geojson\"\n",
    "buildings_key = os.path.join(building_labels_path, buildings_filename)\n",
    "full_buildings_filename = os.path.join(\"/tmp\", buildings_filename)\n",
    "\n",
    "if (not os.path.isfile(full_buildings_filename)):\n",
    "    transfer.download_file(\n",
    "        bucket=bucket, key=buildings_key, filename=full_buildings_filename,\n",
    "        extra_args={\"RequestPayer\": \"requester\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Wrangling imagery with [GDAL](http://www.gdal.org/gdal_translate.html)\n",
    "The downloaded imagery is JPEG compressed, and [GeoTrellis's Decompressor.scala](https://github.com/locationtech/geotrellis/blob/master/raster/src/main/scala/geotrellis/raster/io/geotiff/compression/Decompressor.scala#L119-L122) throws an exceptin, stating that \"Compression type JPEG is not supported by this reader.\" The [Python binding]() of The [gdal_translate](http://www.gdal.org/gdal_translate.html) utility can convert the image to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making directory for converted images, if not created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spacenet_data_path = os.path.join(tmp_path, \"spacenet-data\")\n",
    "if not os.path.exists(spacenet_data_path):\n",
    "    os.makedirs(spacenet_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting imagery to remove JPEG compression, if not converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "\n",
    "for mosiac_3band_key in mosaic_3band_key_list:\n",
    "    mosiac_3band_name = mosiac_3band_key.split(\"/\")[-1]\n",
    "    mosiac_3band_filename = os.path.join(tmp_path, mosiac_3band_name)\n",
    "    translated_mosiac_3band_filename = os.path.join(spacenet_data_path, mosiac_3band_name)\n",
    "    if (not os.path.isfile(mosiac_3band_filename)):\n",
    "        gdal.Translate(\n",
    "            destName=translated_mosiac_3band_filename, srcDS=mosiac_3band_filename,\n",
    "            creationOptions=['COMPRESS=LZW'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Ingesting imagery for fast viewing with [GeoPySpark](https://github.com/locationtech-labs/geopyspark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Setting up Spark context for ingest of Rio imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopyspark as gps\n",
    "from pyspark import SparkContext\n",
    "conf = gps.geopyspark_conf(\"local[*]\", \"spacenet-ingest\")\n",
    "sc = SparkContext.getOrCreate(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingesting Rio imagery files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1035, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 883, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1040, in send_command\n",
      "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:40417)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-11-dd4ced2fca34>\", line 10, in <module>\n",
      "    metadata = rdd.collect_metadata()\n",
      "  File \"/home/hadoop/.local/lib/python3.4/site-packages/geopyspark/geotrellis/layer.py\", line 489, in collect_metadata\n",
      "    json_metadata = self.srdd.collectMetadata(layout)\n",
      "  File \"/usr/local/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/usr/local/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 327, in get_return_value\n",
      "    format(target_id, \".\", name))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o29.collectMetadata\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 1821, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 827, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 963, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o29.collectMetadata",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-dd4ced2fca34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayerType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSPATIAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatalog_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Error: https://github.com/locationtech/geotrellis/issues/2268\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# tile the rdd to the layout defined in the metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hadoop/.local/lib/python3.4/site-packages/geopyspark/geotrellis/layer.py\u001b[0m in \u001b[0;36mcollect_metadata\u001b[0;34m(self, layout)\u001b[0m\n\u001b[1;32m    487\u001b[0m         \"\"\"\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m         \u001b[0mjson_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mMetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m             raise Py4JError(\n\u001b[1;32m    326\u001b[0m                 \u001b[0;34m\"An error occurred while calling {0}{1}{2}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 format(target_id, \".\", name))\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o29.collectMetadata"
     ]
    }
   ],
   "source": [
    "from geopyspark.geotrellis.geotiff import get\n",
    "from geopyspark.geotrellis.constants import LayerType\n",
    "from geopyspark.geotrellis.catalog import write\n",
    "\n",
    "# Read the GeoTiff locally\n",
    "catalog_uri = spacenet_data_path\n",
    "\n",
    "rdd = get(LayerType.SPATIAL, catalog_uri)\n",
    "# Error: https://github.com/locationtech/geotrellis/issues/2268\n",
    "metadata = rdd.collect_metadata()\n",
    "\n",
    "# tile the rdd to the layout defined in the metadata\n",
    "laid_out = rdd.tile_to_layout(metadata)\n",
    "\n",
    "# reproject the tiled rasters using a ZoomedLayoutScheme\n",
    "reprojected = laid_out.reproject(\"EPSG:3857\").cache().repartition(200)\n",
    "\n",
    "# pyramid the TiledRasterRDD to create 12 new TiledRasterRDDs\n",
    "# one for each zoom level\n",
    "pyramided = reprojected.pyramid(start_zoom=12, end_zoom=1)\n",
    "\n",
    "# Save each TiledRasterRDD locally\n",
    "for tiled in pyramided:\n",
    "    write(\"file:///tmp/spacenet-catalog\", \"spacenet-ingest\", tiled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Showing Rio’s outline, imagery, and building footprints on a map with [GeoNotebook](https://github.com/OpenGeoscience/geonotebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading geojson of Rio outline to vector data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from geonotebook.wrappers import VectorData\n",
    "outline_vector = VectorData(outline_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centering map at centroid of Rio outline vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outline_polygons = [polygon for polygon in outline_vector.polygons]\n",
    "outline_polygon = outline_polygons[0]\n",
    "outline_centroid = outline_polygon.centroid\n",
    "x = outline_centroid.x\n",
    "y = outline_centroid.y\n",
    "z = 12\n",
    "M.set_center(x, y, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding layer of Rio outline vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M.add_layer(outline_vector, name=outline_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# buildings_vector = VectorData(buildings_filename)\n",
    "# M.add_layer(building_vector, name=buildings_name);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeoNotebook + GeoPySpark",
   "language": "python",
   "name": "geonotebook3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
